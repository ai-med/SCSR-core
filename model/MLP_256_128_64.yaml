layers:
  - type: Linear
    in_features: 256  # This will be dynamically set based on the input data
    out_features: 128
  - type: BatchNorm1d
  - type: SiLU
  - type: Linear
    in_features: 128
    out_features: 64
  - type: BatchNorm1d
  - type: SiLU
  - type: Dropout
    p: 0.5
  - type: Linear
    in_features: 64
    out_features: 128
  - type: BatchNorm1d
  - type: SiLU
  - type: Linear
    in_features: 128
    out_features: 256  # This should match the `in_features` of the first layer
